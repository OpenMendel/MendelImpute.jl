var documenterSearchIndex = {"docs":
[{"location":"man/script/#Run-MendelImpute-as-script","page":"Run MendelImpute as script","title":"Run MendelImpute as script","text":"","category":"section"},{"location":"man/script/","page":"Run MendelImpute as script","title":"Run MendelImpute as script","text":"If you don't want to run MendelImpute.jl in a Julia session (e.g. you want to run batch jobs on a cluster), you can do so by putting the code above in a Julia file. For example, in order to run with 8 threads, create a file called impute.jl which contains:","category":"page"},{"location":"man/script/","page":"Run MendelImpute as script","title":"Run MendelImpute as script","text":"# place these code in a file called impute.jl\nusing MendelImpute, VCFTools, LinearAlgebra\n\n# setup code goes here\nreffile = ARGS[1]       # first command line argument\ntgtfile = ARGS[2]       # second command line argument\nBLAS.set_num_threads(1) # set BLAS threads to 1 (see performance gotchas)\n\n# run MendelImpute with default options\nphase(tgtfile, reffile; outfile=\"mendel.imputed.chr22.vcf.gz\")","category":"page"},{"location":"man/script/","page":"Run MendelImpute as script","title":"Run MendelImpute as script","text":"Then in the terminal/command-prompt, you can do","category":"page"},{"location":"man/script/","page":"Run MendelImpute as script","title":"Run MendelImpute as script","text":"export JULIA_NUM_THREADS=8\njulia impute.jl your.reference.file.jlso your.target.file.vcf.gz","category":"page"},{"location":"man/painting/#Estimating-ancestry","page":"Estimating ancestry","title":"Estimating ancestry","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"If samples in the reference haplotype panel are labeled with a population origin, MendelImpute can also be used for:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Estimate admixed proportions\nChromosome painting","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We use the 1000 genomes chromosome 22 as illustration. Example code to generate plots are presented. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\nusing GeneticVariation\nusing Random\nusing DataFrames\nusing Plots\nusing JLSO","category":"page"},{"location":"man/painting/#Data-preparation","page":"Estimating ancestry","title":"Data preparation","text":"","category":"section"},{"location":"man/painting/#Step-0.-Filter-chromosome-data","page":"Estimating ancestry","title":"Step 0. Filter chromosome data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The original chromosome data are filtered into target and reference panels. Follow detailed example in Phasing and Imputation to obtain the same data.","category":"page"},{"location":"man/painting/#Step-1.-Get-population-data","page":"Estimating ancestry","title":"Step 1. Get population data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Download population code for each 1000 genomes sample via the command below (note wget will probably not work on non-Mac OS). Different population code is explained here. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# run this code in terminal\n# wget -r -l3 -N --no-parent ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"For easier processing, copy the country of origin data into a folder called data. It should look contain these subfolders (where each population code contains the sample IDs that belong to the population):","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":";ls data","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"ACB\nASW\nBEB\nCDX\nCEU\nCHB\nCHS\nCLM\nESN\nFIN\nGBR\nGIH\nGWD\nIBS\nITU\nJPT\nKHV\nLWK\nMSL\nMXL\nPEL\nPJL\nPUR\nSTU\nTSI\nYRI","category":"page"},{"location":"man/painting/#Step-2.-Process-each-sample's-population-origin","page":"Estimating ancestry","title":"Step 2. Process each sample's population origin","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The goal here is to create a Dict{key, value} where each key is a sample ID and the value is the population code. This will be used for both the paint and composition function.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Here the population origin for different samples are encoded in weird subfolder directory way. We process them into the desired dictionary structure.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"df = DataFrame(sample = String[], population = String[])\nrefID_to_population = Dict{String, String}()\nfor population in readdir(\"data/\")\n    population == \".DS_Store\" && continue # skip auxiliary files\n    for sample in readdir(\"data/\" * population)\n        sample == \".DS_Store\" && continue # skip auxiliary files\n        push!(df, (sample, population))\n        refID_to_population[sample] = population\n    end\nend\nrefID_to_population","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Dict{String,String} with 2709 entries:\n  \"HG01791\" => \"GBR\"\n  \"HG02736\" => \"PJL\"\n  \"HG00182\" => \"FIN\"\n  \"HG03914\" => \"BEB\"\n  \"HG00149\" => \"GBR\"\n  \"NA12156\" => \"CEU\"\n  \"HG02642\" => \"GWD\"\n  \"HG02851\" => \"GWD\"\n  \"NA19835\" => \"ASW\"\n  \"NA19019\" => \"LWK\"\n  \"HG01131\" => \"CLM\"\n  \"HG03725\" => \"ITU\"\n  \"HG03578\" => \"MSL\"\n  \"NA18550\" => \"CHB\"\n  \"HG02401\" => \"CDX\"\n  \"HG01350\" => \"CLM\"\n  \"HG03973\" => \"ITU\"\n  \"NA07000\" => \"CEU\"\n  \"HG01709\" => \"IBS\"\n  \"HG01395\" => \"PUR\"\n  \"HG02388\" => \"CDX\"\n  \"HG01980\" => \"PEL\"\n  \"HG01979\" => \"PEL\"\n  \"HG01122\" => \"CLM\"\n  \"HG03869\" => \"ITU\"\n  ⋮         => ⋮","category":"page"},{"location":"man/painting/#Step-3.-Compute-phase-information-using-MendelImpute","page":"Estimating ancestry","title":"Step 3. Compute phase information using MendelImpute","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This is equivalent to running a typical imputation. Please ensure that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The output file name ends with .jlso (save output to ultra-compressed format)\nimpute = true (so the output contains the entire chromosome)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note data used here is prepared in Detailed Example.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\"\n@time ph = phase(tgtfile, reffile, outfile=outfile);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:20\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 10.2246 seconds\n        import target data             = 2.21667 seconds\n        import compressed haplotypes   = 8.00795 seconds\n    Computing haplotype pair        = 20.127 seconds\n        BLAS3 mul! to get M and N      = 1.01193 seconds per thread\n        haplopair search               = 18.724 seconds per thread\n        initializing missing           = 0.0977775 seconds per thread\n        allocating and viewing         = 0.273912 seconds per thread\n        index conversion               = 0.00868801 seconds per thread\n    Phasing by win-win intersection = 3.82254 seconds\n        Window-by-window intersection  = 0.559845 seconds per thread\n        Breakpoint search              = 3.23837 seconds per thread\n        Recording result               = 0.00971604 seconds per thread\n    Imputation                     = 0.141786 seconds\n        Imputing missing               = 0.0315422 seconds\n        Writing to file                = 0.110244 seconds\n\n    Total time                      = 34.3168 seconds\n\n 34.316709 seconds (33.53 M allocations: 2.517 GiB, 2.50% gc time)","category":"page"},{"location":"man/painting/#Estimate-admixture-proportions","page":"Estimating ancestry","title":"Estimate admixture proportions","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i]. Thus we simply have to plot the result. This illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-import-necessary-data","page":"Estimating ancestry","title":"Step 1: import necessary data","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# First import compressed reference panel\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\ncompressed_Hunique = JLSO.load(reffile)[:compressed_Hunique]\npanelID = compressed_Hunique.sampleID\n\n# also need target sample's ancestry\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreader = VCF.Reader(openvcf(tgtfile, \"r\"))\ntgtID  = VCF.header(reader).sampleID\nsample_population = [refID_to_population[id] for id in tgtID];","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# here is our sample population (sample 1 is GBR, 4 is CHS, 84 is LWK...etc)\nsample_population","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"100-element Array{String,1}:\n \"GBR\"\n \"FIN\"\n \"CHS\"\n \"CHS\"\n \"CDX\"\n \"CDX\"\n \"PUR\"\n \"PUR\"\n \"PUR\"\n \"PUR\"\n \"GBR\"\n \"CLM\"\n \"IBS\"\n ⋮\n \"MXL\"\n \"ASW\"\n \"ASW\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"TSI\"\n \"GIH\"\n \"GIH\"","category":"page"},{"location":"man/painting/#Step-2:-call-composition-function","page":"Estimating ancestry","title":"Step 2: call composition function","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The composition will compute a list of percentages where composition[i] equals the sample's ancestry (in %) from populations[i]. We are finally using the imputation result stored in ph.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = MendelImpute.unique_populations(refID_to_population)\n@time sample1_comp = composition(ph[1], panelID, refID_to_population) # origin GBR\n@time sample4_comp = composition(ph[4], panelID, refID_to_population) # origin CHS\n@time sample84_comp = composition(ph[84], panelID, refID_to_population) # origin LWK","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.004665 seconds (28 allocations: 2.719 KiB)\n  0.000369 seconds (8 allocations: 1.250 KiB)\n  0.000383 seconds (8 allocations: 1.250 KiB)\n\n\n\n\n\n26-element Array{Float64,1}:\n 0.03159153536944775\n 0.004281873442329377\n 0.0183269450383178\n 0.0025138200248509064\n 0.0014987155576730166\n 0.11780598576459632\n 0.0104802353893189\n 0.21297801484829695\n 0.0338623527918964\n 0.004151394212468068\n 0.07204967308369105\n 0.0002681408026507634\n 0.004550014244980141\n 0.013386690160908423\n 0.06359485840010917\n 0.006903428611102466\n 0.0006188785489751994\n 0.1910251836884204\n 0.01634940661876842\n 0.06281796830671477\n 0.0004357288043074905\n 0.003690527207912069\n 0.11661611095283356\n 0.006875896296544575\n 0.0028884989142691606\n 0.0004381229186168723","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note the first run is slower because Julia has to compile the code. ","category":"page"},{"location":"man/painting/#Step-3:-Plot-the-percentages","page":"Estimating ancestry","title":"Step 3: Plot the percentages","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We computed the population percentages for sample 1, 4, and 84. Here sample1_comp[i] equals the sample's estimated ancestry (in %) from populations[i]. Thus we simply have to create a bar plot for each:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"barplot = bar(sample1_comp, xticks=(1:1:26, populations), xrotation=50, grid=false, \n    ylabel = \"Ancestry proportions\", label=\"Sample 1 (GBR)\", alpha=0.8, legend=:top,\n    xtickfont=font(10), ytickfont=font(11), legendfont=font(9), yguidefontsize=18)\nbar!(barplot, sample4_comp, label=\"Sample 4 (CHS)\", alpha=0.8)\nbar!(barplot, sample84_comp, label=\"Sample 84 (LWK)\", alpha=0.8)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/#Chromosome-painting","page":"Estimating ancestry","title":"Chromosome painting","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"The main function is the paint function. For an imputed sample, it will convert each haplotype segment into a percentage indicating the segment's length in the chromosome. Then the list can be used for easy plotting. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Note: this illustration depends on data preparation above. ","category":"page"},{"location":"man/painting/#Step-1:-Choose-your-colors","page":"Estimating ancestry","title":"Step 1: Choose your colors","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"In this example, colors are arranged such that:","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Blue ≈ European/American\nRed ≈ Asian\nGreen ≈ African","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"Of course, Julia lets you plot your favoriate colors. We pick our colors here: https://mdigi.tools/color-shades/#008000.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# generated here: https://mdigi.tools/color-shades/#008000\n# Blue ≈ European/American, Red ≈ Asian, Green ≈ Africa\ngoodcolors = [colorant\"#c8c8ff\", colorant\"#ffeaea\", colorant\"#ffbfbf\", colorant\"#a4a4ff\",\n    colorant\"#8080ff\", colorant\"#e3ffe3\", colorant\"#aaffaa\", colorant\"#71ff71\", \n    colorant\"#5b5bff\", colorant\"#ff9595\", colorant\"#39ff39\", colorant\"#ff6a6a\",\n    colorant\"#ff4040\", colorant\"#3737ff\", colorant\"#1212ff\", colorant\"#0000c8\", \n    colorant\"#0000a4\", colorant\"#00ff00\", colorant\"#ff1515\", colorant\"#00c600\", \n    colorant\"#ea0000\", colorant\"#bf0000\", colorant\"#008e00\", colorant\"#00005b\",\n    colorant\"#950000\", colorant\"#6a0000\"]","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/#Step-2:-Run-paint-funcion","page":"Estimating ancestry","title":"Step 2: Run paint funcion","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"This function convert the imputed haplotype segments into a list of percentages (one list for each strand). This is simply a post-processing routine so that data can be used for easy plotting later.","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"populations = unique_populations(refID_to_population)\n@time sample1_s1_comp, sample1_s2_comp = paint(ph[1], panelID, refID_to_population)\n@time sample4_s1_comp, sample4_s2_comp = paint(ph[4], panelID, refID_to_population)\n@time sample84_s1_comp, sample84_s2_comp = paint(ph[84], panelID, refID_to_population);","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"  0.000323 seconds (12 allocations: 19.125 KiB)\n  0.000310 seconds (12 allocations: 20.375 KiB)\n  0.000307 seconds (12 allocations: 22.875 KiB)","category":"page"},{"location":"man/painting/#Step-3:-Generate-plots-for-painted-chromosomes","page":"Estimating ancestry","title":"Step 3: Generate plots for painted chromosomes","text":"","category":"section"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"We found the StatsPlots.jl package to be more useful for this purpose, although the code below still did the plotting in a very roundabout way. ","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"# assign a color to each haplotype segment\nsample1_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample1_s1_comp[2]]\nsample1_s1_colors = reshape(sample1_s1_colors, 1, length(sample1_s1_colors))\n\nsample1_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample1_s2_comp[2]]\nsample1_s2_colors = reshape(sample1_s2_colors, 1, length(sample1_s2_colors))\n\nsample4_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample4_s1_comp[2]]\nsample4_s1_colors = reshape(sample4_s1_colors, 1, length(sample4_s1_colors))\n\nsample4_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample4_s2_comp[2]]\nsample4_s2_colors = reshape(sample4_s2_colors, 1, length(sample4_s2_colors))\n\nsample84_s1_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample84_s1_comp[2]]\nsample84_s1_colors = reshape(sample84_s1_colors, 1, length(sample84_s1_colors))\n\nsample84_s2_colors = [goodcolors[findfirst(x -> x == pop, populations)] for pop in sample84_s2_comp[2]]\nsample84_s2_colors = reshape(sample84_s2_colors, 1, length(sample84_s2_colors));","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"using StatsPlots, FixedPointNumbers\n\n# some tedious and roundabout routine for making a bad groupedplot\nsample1_s1l = length(sample1_s1_comp[1])\nsample1_s2l = length(sample1_s2_comp[1])\nsample4_s1l = length(sample4_s1_comp[1])\nsample4_s2l = length(sample4_s2_comp[1])\nsample84_s1l = length(sample84_s1_comp[1])\nsample84_s2l = length(sample84_s2_comp[1])\nmaxlen = max(sample1_s1l, sample1_s2l, sample4_s1l, sample4_s2l, sample84_s1l, sample84_s2l)\n\nmydata = zeros(6, maxlen)\ncopyto!(@view(mydata[1, 1:sample1_s1l]), sample1_s1_comp[1])\ncopyto!(@view(mydata[2, 1:sample1_s2l]), sample1_s2_comp[1])\ncopyto!(@view(mydata[3, 1:sample4_s1l]), sample4_s1_comp[1])\ncopyto!(@view(mydata[4, 1:sample4_s2l]), sample4_s2_comp[1])\ncopyto!(@view(mydata[5, 1:sample84_s1l]), sample84_s1_comp[1])\ncopyto!(@view(mydata[6, 1:sample84_s2l]), sample84_s2_comp[1])\n\nmycolors = Matrix{RGB{Normed{UInt8,8}}}(undef, 6, maxlen)\ncopyto!(@view(mycolors[1, 1:sample1_s1l]), sample1_s1_colors)\ncopyto!(@view(mycolors[2, 1:sample1_s2l]), sample1_s2_colors)\ncopyto!(@view(mycolors[3, 1:sample4_s1l]), sample4_s1_colors)\ncopyto!(@view(mycolors[4, 1:sample4_s2l]), sample4_s2_colors)\ncopyto!(@view(mycolors[5, 1:sample84_s1l]), sample84_s1_colors)\ncopyto!(@view(mycolors[6, 1:sample84_s2l]), sample84_s2_colors)\n\n# axis labels\nxnames = [\"Sample 1 hap1\", \"Sample 1 hap2\", \"Sample 4 hap1\", \"Sample 4 hap2\", \"Sample 84 hap1\", \"Sample 84 hap2\"]\nynames = [\"SNP 1\", \"SNP 208k\", \"SNP 417k\"]\n\n# final plot\nchrom_plt = groupedbar(mydata, bar_position = :stack, bar_width=0.7, label=:none, \n    lw = 0, color=mycolors, xticks=(1:1:6, xnames), yticks=(0:0.5:1, ynames),\n    ytickfont=font(12), xtickfont=font(12), xrotation=20)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"(Image: svg)","category":"page"},{"location":"man/painting/","page":"Estimating ancestry","title":"Estimating ancestry","text":"For more details, please refer to our paper, or file an issue on GitHub. ","category":"page"},{"location":"man/Phasing+and+Imputation/#Preparing-Target-Data","page":"Phasing and Imputation","title":"Preparing Target Data","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute accepts VCF and PLINK files. Please make sure the following are true:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"VCF file ends in .vcf or .vcf.gz (phased or unphased and may contain missing data)\nFor PLINK files, all trios (.bim, .bed, .fam) are present in the same directory\nEach file contains only 1 (non-sex) chromosome\nEvery record (SNP) is present in the reference panel. If this is untrue, you must match markers in 2 VCF files. \nGiven a SNP, it's CHROM, POS, REF, and  ALT fields are the same in target data and reference panel. MendelImpute use SNP position internally to align markers. Note this is not explicitly checked. \nThe position of every SNP is unique: so multiallelic markers should be excluded instead of split (this requirement will eventually be lifted). ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"The following are not necessary but recommended for pre-imputation quality control:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Exclude markers with Hardy-Weinberg p-values  10^-5. \nExclude markers with minor allele frequency  10^-6\nExclude samples with 3 missing genotypes","category":"page"},{"location":"man/Phasing+and+Imputation/#Preparing-Reference-Haplotype-Panel","page":"Phasing and Imputation","title":"Preparing Reference Haplotype Panel","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Reference samples must all be phased and contain no missing genotypes. Reference VCF panels must be compressed into .jlso format first using the compress_haplotypes function. One must specify d: the maximum number of unique haplotypes per window. Larger d slows down computation, but increases accuracy. For most purposes, we recommend d approx 1000. A larger d may be needed for TOPMed data. ","category":"page"},{"location":"man/Phasing+and+Imputation/#Detailed-Example","page":"Phasing and Imputation","title":"Detailed Example","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"We use the 1000 genomes chromosome 22 as an example. As show below, this data contains 424147 SNPs and 2504 samples.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing VCFTools\n\n# compute simple summary statistics\ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\n@show nrecords(data)\n@show nsamples(data);","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"nrecords(data) = 424147\nnsamples(data) = 2504","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"More summary statistics can be computed using the gtstats function in VCFTools.jl, with example usage here.","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-1:-generating-realistic-reference-and-target-data","page":"Phasing and Imputation","title":"Step 1: generating realistic reference and target data","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"First we generate a reference panel and imputation target based on the 1000 genomes data. More specifically, we take the 1000 genomes chromosome 22 and divide it so that ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"100 samples are randomly selected as imputation targets, where\n100k SNPs with minor allele frequency ge 005 are randomly selected to be the typed positions. \n0.1% of typed SNPs are masked (mimicking GWAS errors)\nGenotypes are unphased\nThe remaining 2404 samples are used as reference haplotypes. \nSNPs with duplicate positions are filtered out.\nAll multiallelic markers are filtered out.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Instruction: execute the code below in a Julia session or a Jupyter notebook:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing MendelImpute\nusing VCFTools\nusing Random\n\n# set random seed for reproducibility\nRandom.seed!(2020)\n\n# download example data \ndata = \"chr22.1kg.phase3.v5a.vcf.gz\"\nif !isfile(data) \n    download(\"http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.vcf/chr22.1kg.phase3.v5a.vcf.gz\")\nend\n\n# remove SNPs with the same positions, keep all samples, save result into new file\nSNPs_to_keep = .!find_duplicate_marker(data) \n@time VCFTools.filter(data, SNPs_to_keep, 1:nsamples(data), des = \"chr22.uniqueSNPs.vcf.gz\")\n\n# summarize data\ntotal_snps, samples, _, _, _, maf_by_record, _ = gtstats(\"chr22.uniqueSNPs.vcf.gz\")\n\n# generate target file with 100 samples and 100k snps with maf>0.05\nn = 100\np = 100000\nrecord_idx = falses(total_snps)\nlarge_maf = findall(x -> x > 0.05, maf_by_record)  \nRandom.shuffle!(large_maf)\nrecord_idx[large_maf[1:p]] .= true\nsample_idx = falses(samples)\nsample_idx[1:n] .= true\nRandom.shuffle!(sample_idx)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", record_idx, sample_idx, \n    des = \"target.chr22.typedOnly.vcf.gz\", allow_multiallelic=false)\n\n# unphase and mask 0.1% entries in target file\nmasks = falses(p, n)\nmissingprop = 0.001\nfor j in 1:n, i in 1:p\n    rand() < missingprop && (masks[i, j] = true)\nend\n@time mask_gt(\"target.chr22.typedOnly.vcf.gz\", masks, \n    des=\"target.chr22.typedOnly.masked.vcf.gz\", unphase=true)\n\n# generate target panel with all snps (this file contains true phase and genotypes)\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, \n    sample_idx, des = \"target.chr22.full.vcf.gz\", allow_multiallelic=false)\n\n# generate reference panel with 2404 samples\n@time VCFTools.filter(\"chr22.uniqueSNPs.vcf.gz\", 1:total_snps, .!sample_idx, \n    des = \"ref.chr22.excludeTarget.vcf.gz\", allow_multiallelic=false)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"┌ Info: Precompiling MendelImpute [e47305d1-6a61-5370-bc5d-77554d143183]\n└ @ Base loading.jl:1278\n\u001b[32mfinding duplicate markers...100%|███████████████████████| Time: 0:03:56\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:46\u001b[39m\n\n\n292.131527 seconds (3.20 G allocations: 301.789 GiB, 7.89% gc time)\n\n\n\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:02\u001b[39m\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:03:59\u001b[39m\n\n\n244.425505 seconds (3.18 G allocations: 301.694 GiB, 9.69% gc time)\n  1.935526 seconds (20.00 M allocations: 1.491 GiB, 6.33% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:04:10\u001b[39m\n\n\n255.505399 seconds (3.27 G allocations: 317.749 GiB, 9.95% gc time)\n\n\n\u001b[32mfiltering vcf file...100%|██████████████████████████████| Time: 0:07:27\u001b[39m\n\n\n453.383147 seconds (6.16 G allocations: 566.535 GiB, 10.16% gc time)","category":"page"},{"location":"man/Phasing+and+Imputation/#Output-explanation:","page":"Phasing and Imputation","title":"Output explanation:","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You just generated reference and target VCF files:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"ref.chr22.excludeTarget.vcf.gz: Reference haplotype panel with 2404 samples\ntarget.chr22.typedOnly.masked.vcf.gz: Imputation target file containing 100 samples at 100k SNPs. All genotypes are unphased and contains 0.1% missing data. ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"You also generated/downloaded:","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"chr22.1kg.phase3.v5a.vcf.gz: The original chromosome 22 data downloaded from Beagle's website.\nchr22.uniqueSNPs.vcf.gz: This is the original chromosome 22 data excluding duplicate records (SNPs) by checking marker positions. The first SNP is included but all subsequent SNPs are removed. \ntarget.chr22.full.vcf.gz: The complete data for imputation target, used for checking imputation accuracy. All genotypes are phased and non-missing. \ntarget.chr22.typedOnly.vcf.gz: Complete target data on just the typed SNPs. All genotypes are phased and non-missing. Just by-producted for generating other files; not used for anything downstream.","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-2:-generating-.jlso-compressed-reference-panel","page":"Phasing and Imputation","title":"Step 2: generating .jlso compressed reference panel","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute requires one to pre-process the reference panel for faster reading. This is achieved via the compress_haplotypes function.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# load necessary packages in Julia\nusing MendelImpute\n\nmax_d = 1000 # maximum number of unique haplotypes per window\nreffile = \"ref.chr22.excludeTarget.vcf.gz\"\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\noutfile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\n@time compress_haplotypes(reffile, tgtfile, outfile, max_d)","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:02:00\u001b[39m\n\n\n295.546081 seconds (2.09 G allocations: 209.215 GiB, 10.53% gc time)","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-3:-Run-imputation-and-phasing","page":"Phasing and Imputation","title":"Step 3: Run imputation and phasing","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Below runs the main phase function in a single thread. By default all output genotypes will be phased and non-missing. A list of optional inputs can be found in the API.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"# note: run twice for more accurate timing\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\" # jlso reference file\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"  # target genotype file\noutfile = \"mendel.imputed.chr22.vcf.gz\"           # output file name\nphase(tgtfile, reffile; outfile=outfile);","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:22\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 11.7924 seconds\n        import target data             = 2.19475 seconds\n        import compressed haplotypes   = 9.59764 seconds\n    Computing haplotype pair        = 22.7438 seconds\n        BLAS3 mul! to get M and N      = 1.02485 seconds per thread\n        haplopair search               = 17.9195 seconds per thread\n        initializing missing           = 0.10093 seconds per thread\n        allocating and viewing         = 0.23331 seconds per thread\n        index conversion               = 0.0167426 seconds per thread\n    Phasing by win-win intersection = 4.82003 seconds\n        Window-by-window intersection  = 0.470939 seconds per thread\n        Breakpoint search              = 3.18628 seconds per thread\n        Recording result               = 0.191996 seconds per thread\n    Imputation                     = 3.53341 seconds\n        Imputing missing               = 0.153846 seconds\n        Writing to file                = 3.37957 seconds\n\n    Total time                      = 43.0812 seconds","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Inputs after the first ; are all optional. The second ; hides the output, or else the screen will be too jammed. ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"note: Note\nTo run MendelImpute in parallel, type export JULIA_NUM_THREADS=4 before starting Julia. See Performance Gotchas #1 on the left for details.","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-3.5:-(only-for-simulated-data)-check-imputation-accuracy","page":"Phasing and Imputation","title":"Step 3.5: (only for simulated data) check imputation accuracy","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"Since we simulated data, we can check imputation accuracy.","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\")    # import true genotypes\nX_mendel = convert_gt(Float64, \"mendel.imputed.chr22.vcf.gz\") # import imputed genotypes\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"error overall = 0.00527504782243333","category":"page"},{"location":"man/Phasing+and+Imputation/#Step-4:-Post-Imputation-Quality-Control","page":"Phasing and Imputation","title":"Step 4: Post-Imputation Quality Control","text":"","category":"section"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"MendelImpute also computes a rough quality score (file ending in sample.error) for measuring how well each sample is imputed. This value is the sum of the least squares error in each window. A value of 0 is best, and high values mean worse. For more detail, please refer to our paper. ","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"using CSV, UnicodePlots\nquality = CSV.read(\"mendel.imputed.chr22.sample.error\") # import quality score \nhistogram(quality[:error]) # plot in histogram","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"\u001b[90m                  ┌                                        ┐\u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m  0.0\u001b[90m, \u001b[0m100.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇\u001b[39m\u001b[0m 2                                     \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m100.0\u001b[90m, \u001b[0m200.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 58 \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m200.0\u001b[90m, \u001b[0m300.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇▇▇▇▇▇\u001b[39m\u001b[0m 17                          \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m300.0\u001b[90m, \u001b[0m400.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇\u001b[39m\u001b[0m 7                                  \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m400.0\u001b[90m, \u001b[0m500.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇▇▇▇▇\u001b[39m\u001b[0m 9                                \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m500.0\u001b[90m, \u001b[0m600.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 3                                    \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m600.0\u001b[90m, \u001b[0m700.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇▇\u001b[39m\u001b[0m 3                                    \u001b[90m \u001b[39m \n   \u001b[0m\u001b[90m[\u001b[0m700.0\u001b[90m, \u001b[0m800.0\u001b[90m)\u001b[0m\u001b[90m ┤\u001b[39m\u001b[32m▇\u001b[39m\u001b[0m 1                                     \u001b[90m \u001b[39m \n\u001b[90m                  └                                        ┘\u001b[39m \n\u001b[0m                                  Frequency","category":"page"},{"location":"man/Phasing+and+Imputation/","page":"Phasing and Imputation","title":"Phasing and Imputation","text":"We want this histogram to look like this: most samples have small error (well imputed), and only a few have large error (not imputed well, relatively speaking). A histogram with large right tail indicates poor imputation. ","category":"page"},{"location":"man/ultra+compress/#Ultra-compressed-format","page":"Ultra compression","title":"Ultra-compressed format","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"One can optionally save/load ultra-compressed phased genotypes after imputation. Ultra-compression is nothing fancy. Instead of converting haplotype segments into genotypes, this protocol simply saves the starting position and the correct haplotype label. We put this result into our own data structure, and saving/loading is achieved by the JLSO package. ","category":"page"},{"location":"man/ultra+compress/#Saving","page":"Ultra compression","title":"Saving","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Appending .jlso to the output file name will signal MendelImpute to save data in ultra-compressed format. For admixture estimation, we strongly recommend one to save in .jlso format.","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# first load all necessary packages\nusing MendelImpute\nusing VCFTools\n\n# compute each person's phase information\ntgtfile = \"target.chr22.typedOnly.masked.vcf.gz\"\nreffile = \"ref.chr22.maxd1000.excludeTarget.jlso\"\noutfile = \"mendel.imputed.jlso\" # output file name ends in jlso!\n@time phaseinfo = phase(tgtfile, reffile, outfile=outfile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Number of threads = 1\nImporting reference haplotype data...\n\n\n\u001b[32mComputing optimal haplotypes...100%|████████████████████| Time: 0:00:23\u001b[39m\n\u001b[32mPhasing...100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n\n\nTotal windows = 1634, averaging ~ 508 unique haplotypes per window.\n\nTimings: \n    Data import                     = 14.5022 seconds\n        import target data             = 3.87545 seconds\n        import compressed haplotypes   = 10.6268 seconds\n    Computing haplotype pair        = 23.5375 seconds\n        BLAS3 mul! to get M and N      = 1.02915 seconds per thread\n        haplopair search               = 18.3499 seconds per thread\n        initializing missing           = 0.100449 seconds per thread\n        allocating and viewing         = 0.286666 seconds per thread\n        index conversion               = 0.00989394 seconds per thread\n    Phasing by win-win intersection = 5.48704 seconds\n        Window-by-window intersection  = 0.552811 seconds per thread\n        Breakpoint search              = 3.94575 seconds per thread\n        Recording result               = 0.0102354 seconds per thread\n    Imputation                     = 3.7252 seconds\n        Imputing missing               = 0.140427 seconds\n        Writing to file                = 3.58477 seconds\n\n    Total time                      = 47.4236 seconds\n\n 62.687155 seconds (127.92 M allocations: 7.048 GiB, 4.93% gc time)","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The object saved to mendel.imputed.jlso is literally the phaseinfo variable. We can inspect its element:","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"# look at sample 1's haplotype segments\nhaplotype_labels = phaseinfo[1].strand1.haplotypelabel # strand1\nhaplotype_start = phaseinfo[1].strand1.start # strand1\n[haplotype_start haplotype_labels]","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"545×2 Array{Int64,2}:\n      1  4119\n    236   887\n    423   272\n    622    12\n    741   124\n    792     4\n    824    24\n    944  1282\n   1116  1741\n   1202  4543\n   1691  1198\n   3031    22\n   3521    18\n      ⋮  \n 411702   877\n 412185    74\n 413733  3849\n 413868   248\n 414371    31\n 414552  3187\n 414989  4481\n 415807     5\n 415965   143\n 416352  1276\n 416744    71\n 417014   311","category":"page"},{"location":"man/ultra+compress/#Loading","page":"Ultra compression","title":"Loading","text":"","category":"section"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"The function convert_compressed will load the ultra-compressed data into genotype matrices and the original phaseinfo data structure. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Note: Decompressing requires loading the original haplotype reference panel. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"tgtfile = \"mendel.imputed.jlso\" # ultra-compressed genotypes after phasing & imputation\nreffile = \"ref.chr22.excludeTarget.vcf.gz\" # original haplotype reference file\nX1, X2, phaseinfo, sampleID, H = convert_compressed(Float64, tgtfile, reffile);","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"\u001b[32mimporting reference data...100%|████████████████████████| Time: 0:01:55\u001b[39m","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"Check this compression protocol exhibit same error rate with standard VCF compression. Note that X1, X2, and H are transposed. ","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"X_truth  = convert_gt(Float64, \"target.chr22.full.vcf.gz\") # import true genotypes\nX_mendel = (X1 + X2)' # transpose X1 and X2\nn, p = size(X_mendel)\nprintln(\"error overall = $(sum(X_mendel .!= X_truth) / n / p)\")","category":"page"},{"location":"man/ultra+compress/","page":"Ultra compression","title":"Ultra compression","text":"error overall = 0.00527504782243333","category":"page"},{"location":"man/performance/#Performance-gotchas","page":"Performance Gotchas","title":"Performance gotchas","text":"","category":"section"},{"location":"man/performance/#Gotcha-1:-Run-MendelImpute-in-parallel","page":"Performance Gotchas","title":"Gotcha 1: Run MendelImpute in parallel","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"To run MendelImpute.jl in parallel,","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"To use 4 threads, execute export JULIA_NUM_THREADS=4 before starting Julia. \nVerify the Julia session is running is parallel by executing Threads.nthreads() in Julia\nSet the number of BLAS threads to be 1 by using LinearAlgebra; BLAS.set_num_threads(1). This avoids oversubscription. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"note: Note\nWe recommend number of threads equal to the number of physical CPU cores on your machine. Number of Julia threads should never exceed number of physical CPU cores!! Hyperthreading is valuable for I/O operations (in our experience), but not for linear algebra routines used throughout MendelImpute. ","category":"page"},{"location":"man/performance/#Gotcha-2:-max_d-too-high-(or-too-low)","page":"Performance Gotchas","title":"Gotcha 2: max_d too high (or too low)","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"When you compress the haplotype panels into a .jlso format, you specified max_d which is the maximum number of unique haplotypes per window. We generally recommend using max_d = 1000, BUT 1000 may be too small if you use a reference panel larger than HRC. In that case, you can try larger max_d, which will improve error rate. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-high:","page":"Performance Gotchas","title":"Symptoms for max_d too high:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Computing optimal haplotypes is too slow. In particular, the timing for haplopair search is too high. ","category":"page"},{"location":"man/performance/#Symptoms-for-max_d-too-low:","page":"Performance Gotchas","title":"Symptoms for max_d too low:","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"Too few typed SNPs per window indicates max_d is set too low. You can calculate the number of typed SNPs per window by dividing the total number of SNPs in the target file by the total windows (a number that will be output after every run). Ideally you want an average of 400 typed SNPs per window, but something as low as 50 still works. Something like 10~20 is too low. ","category":"page"},{"location":"man/performance/#I-really-want-to-use-a-high-max_d","page":"Performance Gotchas","title":"I really want to use a high max_d","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"A high max_d generally improve error, so it is understandable you want to do so. If a high max_d value runs too slow, try setting stepwise = 100 and max_haplotypes to a number that is close to 1000. This avoids searching the global minimizer of the least-squares problem for windows that have more than max_haplotypes number of unique haplotypes. Setting thinning_factor instead of stepwise have a similar effect. Details for these 2 heuristic searches are explained in the appendix of our paper. ","category":"page"},{"location":"man/performance/#Gotcha-3:-Do-you-have-enough-memory-(RAM)?","page":"Performance Gotchas","title":"Gotcha 3: Do you have enough memory (RAM)?","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"While MendelImpute uses the least RAM compared to competing softwares (as of 2020), it is still possible for large imputation problems to consume all available RAM. If this happens, Julia will first try to use swap before crashing (until all of swap is consumed). Monitor your RAM usage constantly to make sure this doesn't happen. On Mac/Linux machines, the top or htop command will monitor this information. Alternatively, the /usr/bin/time command will automatically records max RAM usage for job and whether any swap had been performed. ","category":"page"},{"location":"man/performance/#Rough-estimate-for-amount-of-RAM-needed","page":"Performance Gotchas","title":"Rough estimate for amount of RAM needed","text":"","category":"section"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"There are 4 things that require lots of memory:","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"The target genotype matrix mathbfX_n times p requires n times p times 8 bits. If mathbfX is dosage data, then you need instead n times p times 32 bits\nThe matrix mathbfM_d times d requires c times d times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe matrix mathbfN_n times d requires c times n times d times 32 bits, where c is the number of parallel threads used and d is the number specified in the compress_haplotypes function.\nThe compressed reference haplotype panel produced by the compress_haplotypes function. This typically requires about 3r gigabytes of RAM where r is your panel's size in .vcf.gz. ","category":"page"},{"location":"man/performance/","page":"Performance Gotchas","title":"Performance Gotchas","text":"If you do not have the above issues and your code is still running slow, file an issue on GitHub and we will take a look at it ASAP. ","category":"page"},{"location":"#MendelImpute.jl","page":"Home","title":"MendelImpute.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Fast genotype imputation, phasing, and admixture estimation!","category":"page"},{"location":"","page":"Home","title":"Home","text":"MendelImpute.jl is the fastest and most memory-efficient software for phasing and genotype imputation, as of 2020. It is also capable of local and global ancestry estimation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a target genotype file (phased or unphased and may contain missing data) and a reference haplotype file (phased, no missing), our software imputes every SNP in the reference file to the target file, outputing phased or unphased genotypes. Like many other software, SNPs typed in target must all be present in the reference panel. ","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Built-in support for imputing genotypes stored in VCF files (.vcf, .vcf.gz) or PLINK files.\nOut-of-the-box multithreaded (shared memory) parallelism. \nAdmixture estimation, with code examples to make pretty plots!\nUltra-compressed file for phased genotypes.\nImputation on dosage data.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Download and install Julia. Within Julia, copy and paste the following: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/SnpArrays.jl.git\"))\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/VCFTools.jl.git\"))\nPkg.add(PackageSpec(url=\"https://github.com/OpenMendel/MendelImpute.jl.git\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package supports Julia v1.5+.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/Phasing+and+Imputation.md\"\n    \"man/performance.md\"\n    \"man/painting.md\"\n    \"man/ultra+compress.md\"\n    \"man/script.md\"\n    \"man/api.md\"\n]\nDepth = 2","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Documentation for MendelImpute.jl's functions.","category":"page"},{"location":"man/api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"man/api/#Functions","page":"API","title":"Functions","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"phase\ncompress_haplotypes\npaint\ncomposition\nunique_populations\nconvert_compressed","category":"page"},{"location":"man/api/#MendelImpute.phase","page":"API","title":"MendelImpute.phase","text":"phase(tgtfile::String, reffile::String; [outfile::String], [impute::Bool],\n    [phase::Bool], [dosage::Bool], [recreen::Bool], [max_haplotypes::Int], \n    [stepwise::Int], [thinning_factor::Int], [scale_allelefreq::Bool], \n    [dynamic_programming::Bool])\n\nMain function of MendelImpute program. Phasing (haplotying) of tgtfile from a pool of haplotypes reffile by sliding windows and saves result in outfile. All SNPs in tgtfile must be present in reffile. Per-sample imputation score (lower is better) will be saved in a file ending in sample.error.\n\nInput\n\ntgtfile: VCF or PLINK files. VCF files should end in .vcf or .vcf.gz.   PLINK files should exclude .bim/.bed/.fam suffixes but the trio must all   be present in the same directory.\nreffile: Reference haplotype file ending in .vcf, .vcf.gz, or .jlso    (compressed binary files).\n\nOptional Inputs\n\noutfile: output filename ending in .vcf.gz, .vcf, or .jlso. VCF output   genotypes will have no missing data. If ending in .jlso, will output   ultra-compressed data structure recording HaplotypeMosaicPairs for    each sample\nimpute: If true, imputes every SNPs in reffile to tgtfile. Otherwise   only missing snps in tgtfile will be imputed.\nphase: If true, all output genotypes will be phased. Otherwise all   output genotypes will be unphased.\ndosage: If true, will assume target matrix are dosages for imputation. Note   this means the genotype matrix will be entirely    single precision. \nrescreen: This option saves a number of top haplotype pairs when solving   the least squares objective, and re-minimize least squares on just   observed data.\nmax_haplotypes Maximum number of haplotypes for using global search. Windows   exceeding this number of unique haplotypes will be searched using a   heuristic. A non-zero stepscreen or thinning_factor need to be specified \nstepwise: If an integer is specified, will solve the least squares objective   by first finding stepwise top haplotypes using a stepwise heuristic then   finds the next haplotype using global search.\nthinning_factor: If an integer is specified, will solve the least squares   objective on only thining_factor unique haplotypes.\nscale_allelefreq: Boolean indicating whether to give rare SNPs more weight   scaled by wᵢ = 1 / √2p(1-p) where max weight is 2. \ndynamic_programming: Boolean indicating whether to phase with a global    search that finds the longest haplotype stretch over all windows.\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.compress_haplotypes","page":"API","title":"MendelImpute.compress_haplotypes","text":"compress_haplotypes(reffile::String, tgtfile::String, outfile::String, \n    [d::Int], [minwidth::Int], [overlap::Float64])\n\nCuts a haplotype matrix reffile into windows of variable width so that each window has less than d unique haplotypes. Saves result to outfile as a compressed binary format. All SNPs in tgtfile must be present in reffile. \n\nWhy is tgtfile required?\n\nThe unique haplotypes in each window is computed on the typed SNPs only.  A genotype matrix tgtfile is used to identify the typed SNPs. In the future,  hopefully we can pre-compute compressed haplotype panels for all genotyping  platforms and provide them as downloadable files. But currently, users must run this function by themselves. \n\nInputs\n\nreffile: reference haplotype file name (ends in .vcf or .vcf.gz)\ntgtfile: target genotype file name (ends in .vcf or .vcf.gz)\noutfile: Output file name (ends in .jlso)\n\nOptional Inputs\n\nd: Max number of unique haplotypes per genotype window (default d = 1000). \nminwidth: Minimum number of typed SNPs per window (default 0)\noverlap: How much overlap between adjacent genotype windows in percentage of   each window's width (default 0.0)\n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.paint","page":"API","title":"MendelImpute.paint","text":"paint(sample_phase::HaplotypeMosaicPair, panelID::Vector{String},\n    refID_to_population::Dict{String, String}, populations::Vector{String})\n\nConverts a person's phased haplotype lengths into segments of percentages. This function is used for easier plotting a \"painted chromosome\".\n\nInputs\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.composition","page":"API","title":"MendelImpute.composition","text":"composition(sample_phase::HaplotypeMosaicPair, panelID::Vector{String}, \n    refID_to_population::Dict{String, String}, [populations::Vector{String}])\n\nComputes a sample's chromosome composition based on phase information. This function is used for easier plotting a person's admixed proportions.\n\nInputs\n\nsample_phase: A HaplotypeMosaicPair storing phase information for a   sample, includes haplotype start position and haplotype label.\npanelID: Sample ID's in the reference haplotype panel\nrefID_to_population: A dictionary mapping each ID in the haplotype    reference panel to its population origin. \n\nOptional inputs\n\npopulations: A unique list of populations present in refID_to_population\n\nOutput\n\ncomposition: A list of percentages where composition[i] equals the   sample's ancestry (in %) from populations[i] \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.unique_populations","page":"API","title":"MendelImpute.unique_populations","text":"unique_populations(x::Dict{String, String})\n\nComputes the unique list of populations, preserving order. x is a Dict where each sample is a key and populations are values. \n\n\n\n\n\n","category":"function"},{"location":"man/api/#MendelImpute.convert_compressed","page":"API","title":"MendelImpute.convert_compressed","text":"convert_compressed(t<:Real, phaseinfo::String, reffile::String)\n\nConverts phaseinfo into a phased genotype matrix of type t using the full reference haplotype panel H \n\nInputs\n\nt: Type of matrix. If bool, genotypes are converted to a BitMatrix\nphaseinfo: Vector of HaplotypeMosaicPairs stored in .jlso format\nreffile: The complete (uncompressed) haplotype reference file\n\nOutput\n\nX1: allele 1 of the phased genotype. Each column is a sample. X = X1 + X2. \nX2: allele 2 of the phased genotype. Each column is a sample. X = X1 + X2. \nphase: the original data structure after phasing and imputation.\nsampleID: The ID's of each imputed person.  \nH: the complete reference haplotype panel. Columns of H are haplotypes.\n\n\n\n\n\nconvert_compressed(t<:Real, phaseinfo::Vector{HaplotypeMosaicPair}, H::AbstractMatrix)\n\nColumns of H are haplotypes.\n\n\n\n\n\n","category":"function"}]
}
